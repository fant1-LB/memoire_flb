{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b614ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import os\n",
    "import ast\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2768603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images(fichier, image):\n",
    "    df=pd.read_csv(fichier)\n",
    "    liste_coords =df['box'].to_list()\n",
    "    nom_image = image\n",
    "    img = nom_image+\".jpg\"\n",
    "    path=os.getcwd()\n",
    "    img = cv2.imread(image)\n",
    "    image = cv2.imread(path + \"\\\\\"+ img)\n",
    "    \n",
    "    if image is None:\n",
    "            print(f\"Erreur : impossible de charger l'image {img}\")\n",
    "            exit()\n",
    "    if not os.path.exists(path+\"\\\\\"+nom_image):\n",
    "        os.makedirs(nom_image)\n",
    "    compteur=0\n",
    "    for i in liste_coords:\n",
    "        compteur+=1\n",
    "        dico = ast.literal_eval(i)\n",
    "        valeurs=list(dico.values())\n",
    "        print(valeurs)\n",
    "        y1, x1, y2, x2 = int(round(valeurs[0])), int(round(valeurs[1])), int(round(valeurs[2])), int(round(valeurs[3]))\n",
    "        print(x1, x2, y1, y2)\n",
    "        cropped_img= image[x1:x2,y1:y2 ]\n",
    "        cv2.imwrite(f\"{nom_image}\\\\{nom_image}_illus{compteur}.png\", cropped_img)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2d78f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('C:\\\\Users\\\\fanti\\\\Documents\\\\stage_highvision\\\\retrainyolomaison\\\\tests\\\\testphase2\\\\demonstration\\\\Excelsior19240710image1.jpg_annots.csv')\n",
    "\n",
    "liste_coords =df['box'].to_list()\n",
    "print(liste_coords)\n",
    "path=os.getcwd()\n",
    "nom_image =\"Excelsior19240710image1\"\n",
    "img = nom_image+\".jpg\"\n",
    "print(path + \"\\\\\"+ img)\n",
    "image = cv2.imread(path + \"\\\\\"+ img)\n",
    "if image is None:\n",
    "    print(f\"Erreur : impossible de charger l'image {nom_image}\")\n",
    "    exit()\n",
    "compteur=0\n",
    "if not os.path.exists(path+\"\\\\\"+nom_image):\n",
    "    os.makedirs(nom_image)\n",
    "for i in liste_coords:\n",
    "    compteur+=1\n",
    "    dico = ast.literal_eval(i)\n",
    "    valeurs=list(dico.values())\n",
    "    print(valeurs)\n",
    "    y1, x1, y2, x2 = int(round(valeurs[0])), int(round(valeurs[1])), int(round(valeurs[2])), int(round(valeurs[3]))\n",
    "    print(x1, x2, y1, y2)\n",
    "    cropped_img= image[x1:x2,y1:y2 ]\n",
    "    cv2.imwrite(f\"{nom_image}\\\\{nom_image}_illus{compteur}.png\", cropped_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d215ca46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfb4bec",
   "metadata": {},
   "source": [
    "https://medium.com/@kerry.halupka/getting-started-with-openais-clip-a3b8f5277867"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3930230f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def image_grid(imgs, cols):\n",
    "    rows = (len(imgs) + cols - 1) // cols\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
    "    \n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    "    return grid\n",
    "path=os.getcwd()\n",
    "nom_image=\"Excelsior19240710image1\"\n",
    "image_urls=[]\n",
    "for i in range(1,20):\n",
    "    image_urls.append(str(path+\"\\\\\"+nom_image+\"\\\\\"+nom_image+\"_illus\"+str(i)+\".png\"))\n",
    "images = []\n",
    "try:\n",
    "    for url in image_urls:\n",
    "        images.append(Image.open(url))\n",
    "except:\n",
    "    pass\n",
    "\n",
    "grid = image_grid(images, cols=3)\n",
    "display(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acde39b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fichier_texte=str('texte'+nom_image+\".txt\")\n",
    "with open (fichier_texte,'r', encoding=\"utf-8\") as ft:\n",
    "   texte=ft.read()\n",
    "   liste_zones=texte.split(\"ZONE_TEXTE\")\n",
    "   \n",
    "   liste2=[]\n",
    "   for i in range(0, len(liste_zones)):\n",
    "      \n",
    "      if len(liste_zones[i])>= 10 and len(liste_zones[i])<=77:\n",
    "         terme=liste_zones[i].replace(\"\\n\",\"\")\n",
    "         terme=liste_zones[i].replace(\"- \",\"\")\n",
    "         liste2.append(terme)\n",
    "print(liste2)       \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "321e3980",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(text=liste2, images=images, return_tensors=\"pt\", padding=True, do_convert_rgb=False)\n",
    "\n",
    "outputs = model(**inputs)\n",
    "logits_per_image = outputs.logits_per_image  # this is the image-text similarity score\n",
    "probs = logits_per_image.softmax(dim=1)  # we can take the softmax to get the label probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516d0445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(8, 20))\n",
    "\n",
    "for idx in range(len(images)):\n",
    "\n",
    "    # show original image\n",
    "    fig.add_subplot(len(images), 2, 2*(idx+1)-1 )\n",
    "    plt.imshow(images[idx])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    # show probabilities\n",
    "    fig.add_subplot(len(images), 2, 2*(idx+1))\n",
    "    \n",
    "    plt.barh(range(len(probs[0].detach().numpy())),probs[idx].detach().numpy(), tick_label=liste2)\n",
    "    plt.xlim(0,1.0)\n",
    "\n",
    "    plt.subplots_adjust(left=0.1,\n",
    "                        bottom=0.1,\n",
    "                        right=0.9,\n",
    "                        top=0.9,\n",
    "                        wspace=0.2,\n",
    "                        hspace=0.8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "330b66ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(probs)\n",
    "liste_probas =probs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60bd31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (liste_probas)\n",
    "for i in liste_probas:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1922272f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\n"
     ]
    }
   ],
   "source": [
    "probabs_image1=[]\n",
    "for probab in liste_probas[0]:\n",
    "    if probab>=0.4:\n",
    "        probabs_image1.append(liste_probas[0].index(probab))\n",
    "print(probabs_image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb75e13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste2[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81a3371e",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_probas_par_ordre_images=[]\n",
    "\n",
    "for i in range(0,len(liste_probas)):\n",
    "    indices_probas=[]\n",
    "    for probab in liste_probas[i]:\n",
    "        if probab>=0.2:\n",
    "            indices_probas.append(liste_probas[i].index(probab))\n",
    "    liste_probas_par_ordre_images.append(indices_probas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794357d3",
   "metadata": {},
   "source": [
    "Dans la cellule ci dessous, l'indice correspond au numéro de l'image, les chiffres à l'indice dans la liste des morceaux de texte des textes associés à plus de 0,2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b987b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(liste_probas_par_ordre_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37d3164",
   "metadata": {},
   "outputs": [],
   "source": [
    "compteur=1\n",
    "for i in liste_probas_par_ordre_images:\n",
    "    print(f\"image n{compteur}\")\n",
    "    compteur+=1\n",
    "    for y in i:\n",
    "        print(liste2[y])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiamat_environnement",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
