{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4b614ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import os\n",
    "import ast\n",
    "from PIL import Image\n",
    "from deep_translator import GoogleTranslator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cb89dd",
   "metadata": {},
   "source": [
    "## Extraction des images détectées par le Yolo dans des fichiers séparés ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2768603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images(fichier, chemin_image):\n",
    "    df=pd.read_csv(fichier)\n",
    "    liste_coords =df['box'].to_list()\n",
    "        \n",
    "    path=os.getcwd()\n",
    "    \n",
    "    image = cv2.imread(path + \"\\\\\"+ chemin_image)\n",
    "    \n",
    "    if image is None:\n",
    "            print(f\"Erreur : impossible de charger l'image {chemin_image}\")\n",
    "            exit()\n",
    "    nom_dossier = chemin_image.replace(\".jpg\",\"\").replace('images_a_traiter\\\\','')\n",
    "    print(nom_dossier)\n",
    "    if not os.path.exists(path+\"\\\\\"+\"sorties\"+\"\\\\\"+nom_dossier):\n",
    "        os.makedirs(\"sorties\\\\\"+nom_dossier)\n",
    "        print(f\"{nom_dossier} créé\")\n",
    "    compteur=0\n",
    "    for i in liste_coords:\n",
    "        compteur+=1\n",
    "        dico = ast.literal_eval(i)\n",
    "        valeurs=list(dico.values())\n",
    "        \n",
    "        y1, x1, y2, x2 = int(round(valeurs[0])), int(round(valeurs[1])), int(round(valeurs[2])), int(round(valeurs[3]))\n",
    "        cropped_img= image[x1:x2,y1:y2]\n",
    "        cv2.imwrite(f\"sorties\\\\{nom_dossier}\\\\{nom_dossier}_illus{compteur}.png\", cropped_img)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c750042d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excelsior19240710image1\n",
      "Excelsior19240710image1 créé\n",
      "Excelsior19240710image4\n",
      "Excelsior19240710image4 créé\n"
     ]
    }
   ],
   "source": [
    "path=os.getcwd()+\"\\\\images_a_traiter\"\n",
    "for root, dirs, file in os.walk(path):\n",
    "    for image in file:\n",
    "        if \".jpg\" in image:\n",
    "            nom_csv = image+\"_annots.csv\"\n",
    "            chemin_image = \"images_a_traiter\\\\\"+image\n",
    "            extract_images(nom_csv, chemin_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfb4bec",
   "metadata": {},
   "source": [
    "Fonction optionnelle pour afficher les images d'une page sous forme de grille, empruntée à HALUKPA Kerry, \"Getting started with OpenAI's CLIP\", sur Medium, 2023, consulté le 27/08/2025.\n",
    "https://medium.com/@kerry.halupka/getting-started-with-openais-clip-a3b8f5277867"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3930230f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def image_grid(imgs, cols):\n",
    "    rows = (len(imgs) + cols - 1) // cols\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
    "    \n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
    "    return grid\n",
    "\n",
    "\n",
    "def montrer_images(nom_image):\n",
    "    path=os.getcwd()\n",
    "\n",
    "    image_urls=[]\n",
    "    for i in range(1,20):\n",
    "        image_urls.append(str(path+\"\\\\\"+\"sorties\"+\"\\\\\"+nom_image+\"_illus\"+str(i)+\".png\"))\n",
    "    images = []\n",
    "    try:\n",
    "        for url in image_urls:\n",
    "            images.append(Image.open(url))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    grid = image_grid(images, cols=3)\n",
    "    display(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1c4ecdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_integral():\n",
    "    liste_images = obtenir_liste_images()\n",
    "    for i in liste_images:\n",
    "        liste2=obtenir_liste_captions(i)\n",
    "        liste3 = traduire(liste2)\n",
    "        application_CLIP(liste3, i, liste2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c01fefd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtenir_liste_images():\n",
    "    path=os.getcwd()+\"\\\\sorties\"\n",
    "    liste_images = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "            \n",
    "        for dir in dirs:\n",
    "                \n",
    "            liste_images.append(str(dir))\n",
    "    return(liste_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "acde39b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtenir_liste_captions(nom_image):\n",
    "   fichier_texte=str('dossier_output_experience\\\\texte'+nom_image+\".jpg.txt\") #modifier le .jpg selon le format de l'image de la page de journal originale\n",
    "   with open (fichier_texte,'r', encoding=\"utf-8\") as ft:\n",
    "         texte=ft.read()\n",
    "         liste_zones=texte.split(\"Zone_texte\")\n",
    "         \n",
    "         liste2=[]\n",
    "         for i in range(0, len(liste_zones)):\n",
    "            \n",
    "            if len(liste_zones[i])>= 10 and len(liste_zones[i])<=77:\n",
    "               terme=liste_zones[i].replace(\"\\n\",\"\")\n",
    "               terme=liste_zones[i].replace(\"- \",\"\")\n",
    "               liste2.append(terme)\n",
    "   return(liste2)       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5d567f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def traduire(liste2):\n",
    "    liste3= GoogleTranslator(\"fr\",\"en\").translate_batch(liste2)\n",
    "    return(liste3)\n",
    "#Cellule pour passer les textes en anglais, CLIP ayant été entraîné sur des textes en anglais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143c453f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def application_CLIP(liste3, dossier, liste2):\n",
    "    model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "    processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "    images=[]\n",
    "    path= os.getcwd()+\"\\\\sorties\"+\"\\\\\"+dossier\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for image in files:\n",
    "            if \".png\" in image:\n",
    "                image= Image.open(path+\"\\\\\"+image)\n",
    "                images.append(image)\n",
    "        \n",
    "    inputs = processor(text=liste3, images=images, return_tensors=\"pt\", padding=True, do_rescale= True, do_convert_rgb=False)\n",
    "    outputs = model(**inputs)\n",
    "    logits_per_image = outputs.logits_per_image  # this is the image-text similarity score\n",
    "    probs = logits_per_image.softmax(dim=1)  # we can take the softmax to get the label probabilities\n",
    "    liste_probas =probs.tolist()\n",
    "    liste_probas_par_ordre_images=[]\n",
    "\n",
    "    for i in range(0,len(liste_probas)):\n",
    "        indices_probas=[]\n",
    "        for probab in liste_probas[i]:\n",
    "            if probab>=0.4:\n",
    "                indices_probas.append(liste_probas[i].index(probab))\n",
    "        liste_probas_par_ordre_images.append(indices_probas)\n",
    "    compteur=1\n",
    "    for i in liste_probas_par_ordre_images:\n",
    "        print(f\"image n{compteur}\")\n",
    "        compteur+=1\n",
    "        for y in i:\n",
    "            print(liste2[y])\n",
    "    return(probs, liste_probas_par_ordre_images)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cbbc8ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image n1\n",
      " JUILLET 1924 \n",
      "\n",
      " LES EPREUVES OLYMPIQUES AU STADE DE COLOMBES \n",
      "\n",
      "image n2\n",
      " JUILLET 1924 \n",
      "\n",
      " L'ancien président de la Répu\" aspire au repos blique „ de la campagne \n",
      "\n",
      "image n3\n",
      " JUILLET 1924 \n",
      "\n",
      "image n4\n",
      " JUILLET 1924 \n",
      "\n",
      "image n5\n",
      " JUILLET 1924 \n",
      "\n",
      "image n6\n",
      " JUILLET 1924 \n",
      "\n",
      "image n7\n",
      " L'ancien président de la Répu\" aspire au repos blique „ de la campagne \n",
      "\n",
      " Un adversaire du projet \n",
      "\n",
      "image n8\n",
      " JUILLET 1924 \n",
      "\n",
      "image n9\n",
      " JUILLET 1924 \n",
      "\n",
      " LES EPREUVES OLYMPIQUES AU STADE DE COLOMBES \n",
      "\n",
      "image n10\n",
      " JUILLET 1924 \n",
      "\n",
      " LES EPREUVES OLYMPIQUES AU STADE DE COLOMBES \n",
      "\n"
     ]
    }
   ],
   "source": [
    "clip_integral()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516d0445",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def repres_probs(probs):\n",
    "    fig = plt.figure(figsize=(8, 20))\n",
    "\n",
    "    for idx in range(len(images)):\n",
    "\n",
    "        # show original image\n",
    "        fig.add_subplot(len(images), 2, 2*(idx+1)-1 )\n",
    "        plt.imshow(images[idx])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "\n",
    "        # show probabilities\n",
    "        fig.add_subplot(len(images), 2, 2*(idx+1))\n",
    "        \n",
    "        plt.barh(range(len(probs[0].detach().numpy())),probs[idx].detach().numpy(), tick_label=liste2)\n",
    "        plt.xlim(0,1.0)\n",
    "\n",
    "        plt.subplots_adjust(left=0.1,\n",
    "                            bottom=0.1,\n",
    "                            right=0.9,\n",
    "                            top=0.9,\n",
    "                            wspace=0.2,\n",
    "                            hspace=0.8)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330b66ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(probs)\n",
    "liste_probas =probs.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60bd31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (liste_probas)\n",
    "for i in liste_probas:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1922272f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\n"
     ]
    }
   ],
   "source": [
    "probabs_image1=[]\n",
    "for probab in liste_probas[0]:\n",
    "    if probab>=0.4:\n",
    "        probabs_image1.append(liste_probas[0].index(probab))\n",
    "print(probabs_image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a3371e",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_probas_par_ordre_images=[]\n",
    "\n",
    "for i in range(0,len(liste_probas)):\n",
    "    indices_probas=[]\n",
    "    for probab in liste_probas[i]:\n",
    "        if probab>=0.2:\n",
    "            indices_probas.append(liste_probas[i].index(probab))\n",
    "    liste_probas_par_ordre_images.append(indices_probas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794357d3",
   "metadata": {},
   "source": [
    "Dans la cellule ci dessous, l'indice correspond au numéro de l'image, les chiffres à l'indice dans la liste des morceaux de texte des textes associés à plus de 0,2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b987b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(liste_probas_par_ordre_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37d3164",
   "metadata": {},
   "outputs": [],
   "source": [
    "compteur=1\n",
    "for i in liste_probas_par_ordre_images:\n",
    "    print(f\"image n{compteur}\")\n",
    "    compteur+=1\n",
    "    for y in i:\n",
    "        print(liste2[y])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiamat_environnement",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
