{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f5192f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def predict(chosen_model, img, classes=[], conf=0.5):\n",
    "    if classes:\n",
    "        results = chosen_model.predict(img, classes=classes, conf=conf)\n",
    "    else:\n",
    "        results = chosen_model.predict(img, conf=conf)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def predict_and_detect(chosen_model, img, classes=[], conf=0.5, rectangle_thickness=5, text_thickness=1):\n",
    "    results = predict(chosen_model, img, classes, conf=conf)\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            cv2.rectangle(img, (int(box.xyxy[0][0]), int(box.xyxy[0][1])),\n",
    "                          (int(box.xyxy[0][2]), int(box.xyxy[0][3])), (255, 0, 255), rectangle_thickness)\n",
    "            # cv2.putText(img, f\"{result.names[int(box.cls[0])]}\",\n",
    "            #             (int(box.xyxy[0][0]), int(box.xyxy[0][1]) - 10),\n",
    "            #             cv2.FONT_HERSHEY_PLAIN, 1, (255, 0, 0), text_thickness)\n",
    "    return img, results\n",
    "\n",
    "\n",
    "\n",
    "model = YOLO(\"best.pt\")\n",
    "path=os.getcwd()\n",
    "for root, dirs, file in os.walk(path):\n",
    "    for f in file:\n",
    "        if \".jpeg\" in f:\n",
    "    # read the image\n",
    "            image = cv2.imread(os.path.abspath(os.path.join(root,f)))\n",
    "            result_img, results = predict_and_detect(model, image, classes=[], conf=0.5)\n",
    "            \n",
    "            with open(f\"coord_{f}.txt\",'a') as file:\n",
    "                for result in results:\n",
    "                    df=result.to_df()\n",
    "                    df.to_csv(f\"{f}_annots.csv\")\n",
    "                    # for box in result.boxes:\n",
    "                    #      file.write(str(box)+\"\\n\")\n",
    "        # cv2.imshow(\"Image\", result_img)\n",
    "            cv2.imwrite(f\"result{f}.png\", result_img)\n",
    "            cv2.waitKey(0)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5123a2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import configparser\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pero_ocr.core.layout import PageLayout\n",
    "from pero_ocr.document_ocr.page_parser import PageParser\n",
    "import re\n",
    "# from langchain_ollama import ChatOllama\n",
    "# from langchain_core.messages.ai import AIMessage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b09eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Read config file.\n",
    "config_path = \"pero_eu_cz_print_newspapers_2022-09-26\\\\config.ini\"\n",
    "config = configparser.ConfigParser()\n",
    "config.read(config_path)\n",
    "\n",
    "# # Init the OCR pipeline. \n",
    "# # You have to specify config_path to be able to use relative paths\n",
    "# # inside the config file.\n",
    "page_parser = PageParser(config, config_path=os.path.dirname(config_path))\n",
    "\n",
    "\n",
    "# Read the document page image.\n",
    "path=os.getcwd()+\"\\\\dossier_dexperience\"\n",
    "for f in os.listdir(path):\n",
    "        \n",
    "            \n",
    "            input_image_path = f\"dossier_dexperience\\\\{f}\"\n",
    "            image = cv2.imread(input_image_path, 1)\n",
    "\n",
    "            # Init empty page content. \n",
    "            # This object will be updated by the ocr pipeline. id can be any string and it is used to identify the page.\n",
    "            page_layout = PageLayout(id=input_image_path, page_size=(image.shape[0], image.shape[1]))\n",
    "\n",
    "        # Process the image by the OCR pipeline\n",
    "        # try:\n",
    "            page_layout = page_parser.process_page(image, page_layout)\n",
    "\n",
    "\n",
    "            page_layout.to_pagexml(f'dossier_output_experience\\\\output_page{f}.xml') # Save results as Page XML.\n",
    "            page_layout.to_altoxml(f'dossier_output_experience\\\\output_ALTO{f}.xml') # Save results as ALTO XML.\n",
    "            for region in page_layout.regions:\n",
    "                \n",
    "                liste_lignes = [f\"Zone_texte\",]\n",
    "\n",
    "                for line in region.lines:\n",
    "                    liste_lignes.append(line.transcription)\n",
    "\n",
    "                with open(f'dossier_output_experience\\\\texte{f}.txt', 'a', encoding='utf-8') as txt:\n",
    "                    txt.write('\\n')\n",
    "                    for element in liste_lignes:\n",
    "                        txt.write(element +\" \")\n",
    "        # except:\n",
    "        #     print(f\"probleme avec {f}\")\n",
    "        #     pass\n",
    "\n",
    "        # Render detected text regions and text lines into the image and\n",
    "        # save it into a file.\n",
    "            rendered_image = page_layout.render_to_image(image) \n",
    "            cv2.imwrite(f'results_full2\\\\{f}.png', rendered_image)\n",
    "\n",
    "            # Save each cropped text line in a separate .jpg file.\n",
    "            # for region in page_layout.regions:\n",
    "            #     for line in region.lines:\n",
    "            #         cv2.imwrite(f'file_id-{line.id}.jpg', line.crop.astype(np.uint8))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378ddaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def correction_mistral (texte):\n",
    "    llm = ChatOllama(model=\"mistral\", temperature=0 )\n",
    "    messages = [(\"system\",\"You are post correcting OCR results on a 1920 newspaper. If the text is empty or only composed of ponctuation return 'none'.\",\n",
    "    ),(\"human\",f\"{texte}\")]\n",
    "    ai_msg = llm.invoke(messages)\n",
    "    return ai_msg\n",
    "path=os.getcwd()+\"\\\\resulttext_pre_cor\"\n",
    "for file in os.listdir(path):\n",
    "  \n",
    "    print(f\"starting {file}\")\n",
    "    liste_corrigee =[]\n",
    "    with open(f'resulttext_pre_cor\\\\{file}','r') as f:\n",
    "        liste = (f.read()).split('Zone_texte')\n",
    "    for line in liste : \n",
    "        # if re.match(r'\\w', line):\n",
    "        \n",
    "            print(line)\n",
    "            \n",
    "            correc = correction_mistral(line)\n",
    "            print(correc.pretty_repr())\n",
    "            liste_corrigee.append(correc)\n",
    "        # else:\n",
    "        #       print(f\"Ã§a : {line} est pas bon\")\n",
    "        #       pass\n",
    "    \n",
    "    with open(f'resulttext_post_cor\\\\{file}2.txt', 'w') as txt:\n",
    "        for element in liste_corrigee:\n",
    "                        \n",
    "                        txt.write(element.pretty_repr() + \"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f15afc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "import tqdm as notebook_tqdm\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('pykale/bart-base-ocr')\n",
    "tokenizer = AutoTokenizer.from_pretrained('pykale/bart-base-ocr')\n",
    "generator = pipeline('text2text-generation', model=model.to('cuda'), tokenizer=tokenizer, device='cuda', max_length=1024)\n",
    "path=os.getcwd()+\"\\\\resulttext_pre_cor\"\n",
    "for file in os.listdir(path):\n",
    "  \n",
    "   \n",
    "    liste_corrigee =[]\n",
    "    with open(f'resulttext_pre_cor\\\\{file}','r') as f:\n",
    "        liste = (f.read()).split('Zone_texte')\n",
    "    for line in liste : \n",
    "\n",
    "        ocr = line\n",
    "        pred = generator(ocr)[0]['generated_text']\n",
    "        liste_corrigee.append(pred)\n",
    "        print(line)\n",
    "        print(pred)\n",
    "    with open(f'resulttext_post_cor\\\\{file}2.txt', 'w') as txt:\n",
    "        for element in liste_corrigee:\n",
    "                        \n",
    "                        txt.write(element + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiamat_environnement",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
